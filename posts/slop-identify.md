In 2023, Dr. Jared Mumm, a professor at Texas A&M University denied several seniors their diplomas after they had already walked.

These students would be receiving an "X" in the course, as the professor asserted they had written papers with "Chat GTP" (the correct name is "ChatGPT", but you can't expect every professor to get this stuff right). Dr. Mumm backed up his claim by showing he had asked "Chat GTP" if these students' work was written by it. Gleefully it claimed the credit (can't say it's not a go-getter). 

Thankfully he had "tested" each paper in this manner twice, so he felt confident in putting these students' futures on the line. Just a small snag, however... as his dissertation on pig farming written several years before the introduction of "Chat GTP" also appears to be written by it, at least according to it. It also took credit for wholly drafting the same email that Dr. Mumm had sent to the students letting them know they had been "caught".

While the ridiculousness of his claims were easy to test, and the students were able to prove their work using Google Doc timestamps logged as they wrote their papers, this terrifying anecdote raises important questions about the problems of authenticity in work today and if we have the capability to discern if something was written with AI-assistance or not.

For tech companies today this is a quandary. How does Meta know if an image on Instagram is real or fake? Do they care? How does a teacher know if their students' work was AI? What about a manager reviewing his report's suddenly meandering output? What about a report reading his manager's suddenly correctly-spelt emails?

AI content can be pushed out in volumes of epic proportions in the same way that a spam email can be sent to millions of people. Such content is referred to as "Slop". Will the world of media turn into a trough?

We're going to discuss some of the latest attempts to determine this, and how to live in a "slop-py" (full of AI) world. 

### Meta

Meta, the owner of Instagram and Facebook, rushed to solve the problem. [They now accurately label AI-generated images across their platforms](https://about.fb.com/news/2024/02/labeling-ai-generated-images-on-facebook-instagram-and-threads/). Or... at least they tried. Their system [incorrectly labels real photos and lets slop through](https://www.techradar.com/cameras/photography/instagram-is-tagging-real-photos-as-made-with-ai-and-photographers-arent-happy). While there are heuristics that make a photo more or less likely to determine if it was generated by AI (by examining "metadata" within the file), there is no magic bullet. 

It's worth seriously considering what it means if Meta's products cannot discern with certainty between generated content and human-authored content. Never the slouch, Meta has already considered the implications, and they have chosen to go all-in on filling their [troughs with as much as slop as possible, even making fake friends to converse with](https://www.wsj.com/tech/ai/mark-zuckerberg-ai-digital-future-0bb04de7?gaa_at=eafs&gaa_n=ASWzDAhDpTQCsAOr-WioewDjnwS3nXEg2UejWsUPxXr2Md9CW35SSLJBI3_zEAF82wQ%3D&gaa_ts=687ade2a&gaa_sig=nJF7u5zhILB7BybJa4LLLJ5fGyDzEcpG77VYPaqyzPpVePLMq67B-YnWJn4N0jXDDVPyW6GuxO0coslDuLw1FQ%3D%3D). 

This is not an unintelligent approach! If it's not possible to discern or filter this content, then maybe customers will find the content engaging on its merits because by definition, it is at human-quality! Say what you will but Meta is full of go-getters.

### School
While Meta might gleefully welcome the deluge of new high quality content to keep customers engaged, not everybody has the priviledge of leaning in. Schools, as we discussed, are in quite the pickle here.

To encourage students to write their essays with AI defeats the purpose of practicing their authorship and writing ability. It robs them of their own unique voice and robs them of their learning. 

There are already compelling studies showing that [using AI tools decreases activity throughout the brain](https://time.com/7295195/ai-chatgpt-google-learning-school/). Tech companies such as Google are already eager to capture more traffic and happily advertise the benefits of using generative AI inside of search results that may be related to homework (parents should become aware of this). We must act now to protect the development and education of our youth. While the best time to begin was in 2022 when ChatGPT released, today is the second best time.

While many intellectuals posit about ["Zero Trust Homework"](https://stratechery.com/2022/ai-homework/#Zero_Trust_Homework) schemes to design new software systems with accountable generation histories and even purposeful errors, the unfortunate reality is that general access to competent models is here to stay. Thankfully we have a few actionable items to mitigate this:

* There is no reliable way to detect AI
* Shift focus to in person school work
* No phones in the classroom
* AI learning tools

Outside of a possibility that generative models have [a thing for the "em dash"](https://www.washingtonpost.com/technology/2025/04/09/ai-em-dash-writing-punctuation-chatgpt/), there is no reliable way for an educator to discern if content was wholly generated with AI, let alone partially and edited. This may be not what you wanted to hear, but it appears to be the truth. We have to work around it.

A return to in-class essaying or work isn't too hard to grasp, and can effectively fight against the urge to just ask the bot. No phones in classrooms also make it more difficult to ask it for help, as well as the various other benefits that are found in youth who's schools delay the onset-of-first-phone, or active phone usage in class. For more information I highly recommend the book _The Anxious Generation_ by Jonathan Haidt, or his blog: [After Babel](https://www.afterbabel.com/).

Where education gets interesting is the introduction of AI learning tools. AI tools by some measures are one of the most beneficially transformative developments in personalized tutoring. For example, [Duolingo recently introduced 'real life' conversations](https://blog.duolingo.com/video-call/) with an voice-enabled AI to practice your foreign language skills. I've personally used it and it is surreal. Like a real person it will converse with you, repeat words, and correct you. Practice makes perfect and with these tools, practice is more democratized.

This is not exclusive to language learning - while immensely popular youtube-tutor services like Khan Academy have been utilized by students for over a decade now, any run-of-the-mill generative-AI chatbot can walk you through anything in great detail, even starting a garden, testing soil ph, picking plants, understanding climate zones, and increasing your yields in a digestible, auditable way. I personally used it to level up my homebrew set up for creating beer: it explained the sparging process (don't worry about it) with ease and even let me know the minimum equipment necessary to purchase to accomplish it.

Parents should as always be active in their child's education. Sit with them and walk them through their homework and help them query the bot to understand The Why present in the problem they're solving. We just might see the smartest cohort of students to walk this Earth, unlimited by the availability of exacerbated teachers.

### Work
According to [this Gallup poll](https://www.gallup.com/workplace/651203/workplace-answering-big-questions.aspx), 33% of employees say their workplace has already integrated AI. However, two-thirds of employees say they "Never" use it. How to increase adoption amongst the "Never" and how to ensure quality persists among the "Constantly" (not a real response in the survey) crowd could be it's own post.

However, we can discuss some of the high level effects and best practices now. There are two key takeaways I'd like to highlight:

* Below average employees benefit most from generative-AI
* Most employees lack clear guidance on the usage of AI at work

According to the poll, 45% of employees say that "Productivity and efficiency" has improved, but when combined with another interesting survey, you see an impressive pattern. [Below average performers are uplifted](https://www.ethicallyalignedai.com/post/below-average-workers-will-benefit-the-most-from-using-ai) by the availability of such tools, according to [study by the Harvard Business School](https://www.hbs.edu/faculty/Pages/item.aspx?num=64700). Below average workers saw a 43% improvement in their output vs a 17% gain for high performing counterparts. That is a huge win.

While that may be exciting for teams who want to see their coworkers succeed more, workers today do not have clear guidance on the usage of AI. According to the referenced Gallup poll, 70% of all workers say their employer does NOT have an AI policy. This could lead to confusion, the leakage of proprietary information, or even possibly plagiarism if the output is not vetted. This must be a priority for any business today - the risks are large, and the benefits great.

### Conclusion
Across school, the workplace, even the metaverse, AI is changing how we produce and interact. While there may be a deluge of "slop" in some places, others are using it to refine their minds to be sharper than ever before.

It is an exciting time - ask questions, and stay sharp!
